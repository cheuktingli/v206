---
title: Uniformly Conservative Exploration in Reinforcement Learning
abstract: A key challenge to deploying reinforcement learning in practice is avoiding
  excessive (harmful) exploration in individual episodes. We propose a natural constraint
  on explorationâ€”uniformly outperforming a conservative policy (adaptively estimated
  from all data observed thus far), up to a per-episode exploration budget. We design
  a novel algorithm that uses a UCB reinforcement learning policy for exploration,
  but overrides it as needed to satisfy our exploration constraint with high probability.
  Importantly, to ensure unbiased exploration across the state space, our algorithm
  adaptively determines when to explore. We prove that our approach remains conservative
  while minimizing regret in the tabular setting. We experimentally validate our results
  on a sepsis treatment task and an HIV treatment task, demonstrating that our algorithm
  can learn while ensuring good performance compared to the baseline policy for every
  patient; the latter task also demonstrates that our approach extends to continuous
  state spaces via deep reinforcement learning.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu23j
month: 0
tex_title: Uniformly Conservative Exploration in Reinforcement Learning
firstpage: 10856
lastpage: 10870
page: 10856-10870
order: 10856
cycles: false
bibtex_author: Xu, Wanqiao and Ma, Yecheng and Xu, Kan and Bastani, Hamsa and Bastani,
  Osbert
author:
- given: Wanqiao
  family: Xu
- given: Yecheng
  family: Ma
- given: Kan
  family: Xu
- given: Hamsa
  family: Bastani
- given: Osbert
  family: Bastani
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/xu23j/xu23j.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
