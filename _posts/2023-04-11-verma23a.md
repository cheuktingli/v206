---
title: 'Learning to Defer to Multiple Experts: Consistent Surrogate Losses, Confidence
  Calibration, and Conformal Ensembles'
software: https://github.com/rajevv/Multi_L2D
abstract: We study the statistical properties of learning to defer (L2D) to multiple
  experts. In particular, we address the open problems of deriving a consistent surrogate
  loss, confidence calibration, and principled ensembling of experts. Firstly, we
  derive two consistent surrogates—one based on a softmax parameterization, the other
  on a one-vs-all (OvA) parameterization—that are analogous to the single expert losses
  proposed by Mozannar and Sontag (2020) and Verma and Nalisnick (2022), respectively.
  We then study the frameworks’ ability to estimate $P( m_j = y | x )$, the probability
  that the $j$th expert will correctly predict the label for $x$. Theory shows the
  softmax-based loss causes mis-calibration to propagate between the estimates while
  the OvA-based loss does not (though in practice, we find there are trade offs).
  Lastly, we propose a conformal inference technique that chooses a subset of experts
  to query when the system defers. We perform empirical validation on tasks for galaxy,
  skin lesion, and hate speech classification.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: verma23a
month: 0
tex_title: 'Learning to Defer to Multiple Experts: Consistent Surrogate Losses, Confidence
  Calibration, and Conformal Ensembles'
firstpage: 11415
lastpage: 11434
page: 11415-11434
order: 11415
cycles: false
bibtex_author: Verma, Rajeev and Barrejon, Daniel and Nalisnick, Eric
author:
- given: Rajeev
  family: Verma
- given: Daniel
  family: Barrejon
- given: Eric
  family: Nalisnick
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/verma23a/verma23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
