---
title: Convolutional Persistence as a Remedy to Neural Model Analysis
software: https://github.com/khramtsova/conv_persistence.git
abstract: 'While deep neural networks are proven to be effective learning systems,
  their analysis is complex due to the high-dimensionality of their weight space.
  Persistent topological properties can be used as an additional descriptor, providing
  insights on how the network weights evolve during training. In this paper, we focus
  on convolutional neural networks, and define the topology of the space, populated
  by convolutional filters (i.e., kernels). We perform an extensive analysis of topological
  properties of the convolutional filters. Specifically, we define a metric based
  on persistent homology, namely, Convolutional Topology Representation, to determine
  an important factor in neural networks training: the generalizability of the model
  to the test set. We further analyse how various training methods affect the topology
  of convolutional layers.'
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: khramtsova23a
month: 0
tex_title: Convolutional Persistence as a Remedy to Neural Model Analysis
firstpage: 10839
lastpage: 10855
page: 10839-10855
order: 10839
cycles: false
bibtex_author: Khramtsova, Ekaterina and Zuccon, Guido and Wang, Xi and Baktashmotlagh,
  Mahsa
author:
- given: Ekaterina
  family: Khramtsova
- given: Guido
  family: Zuccon
- given: Xi
  family: Wang
- given: Mahsa
  family: Baktashmotlagh
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/khramtsova23a/khramtsova23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
