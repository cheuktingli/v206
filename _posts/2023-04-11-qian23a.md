---
title: Catalyst Acceleration of Error Compensated Methods Leads to Better Communication
  Complexity
abstract: Communication overhead is well known to be a key bottleneck in large scale
  distributed learning, and a particularly successful class of methods which help
  to overcome this bottleneck is based on the idea of communication compression. Some
  of the most practically effective gradient compressors, such as TopK, are biased,
  which causes convergence issues unless one employs a well designed error compensation/feedback
  mechanism. Error compensation is therefore a fundamental technique in the distributed
  learning literature. In a recent development, Qian et al (NeurIPS 2021) showed that
  the error-compensation mechanism can be combined with acceleration/momentum, which
  is another key and highly successful optimization technique. In particular, they
  developed the error-compensated loop-less Katyusha (ECLK) method, and proved an
  accelerated linear rate in the strongly convex case. However, the dependence of
  their rate on the compressor parameter does not match the best dependence obtainable
  in the non-accelerated error-compensated methods. Our work addresses this problem.
  We propose several new accelerated error-compensated methods using the catalyst
  acceleration technique, and obtain results that match the best dependence on the
  compressor parameter in non-accelerated error-compensated methods up to logarithmic
  terms.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: qian23a
month: 0
tex_title: Catalyst Acceleration of Error Compensated Methods Leads to Better Communication
  Complexity
firstpage: 615
lastpage: 649
page: 615-649
order: 615
cycles: false
bibtex_author: Qian, Xun and Dong, Hanze and Zhang, Tong and Richtarik, Peter
author:
- given: Xun
  family: Qian
- given: Hanze
  family: Dong
- given: Tong
  family: Zhang
- given: Peter
  family: Richtarik
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/qian23a/qian23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
