---
title: On Generalization of Decentralized Learning with Separable Data
abstract: Decentralized learning offers privacy and communication efficiency when
  data are naturally distributed among agents communicating over an underlying graph.
  Motivated by overparameterized learning settings, in which models are trained to
  zero training loss, we study algorithmic and generalization properties of decentralized
  learning with gradient descent on separable data. Specifically, for decentralized
  gradient descent (DGD) and a variety of loss functions that asymptote to zero at
  infinity (including exponential and logistic losses), we derive novel finite-time
  generalization bounds. This complements a long line of recent work that studies
  the generalization performance and the implicit bias of gradient descent over separable
  data, but has thus far been limited to centralized learning scenarios. Notably,
  our generalization bounds approximately match in order their centralized counterparts.
  Critical behind this, and of independent interest, is establishing novel bounds
  on the training loss and the rate-of-consensus of DGD for a class of self-bounded
  losses. Finally, on the algorithmic front, we design improved gradient-based routines
  for decentralized learning with separable data and empirically demonstrate orders-of-magnitude
  of speed-up in terms of both training and generalization performance.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: taheri23a
month: 0
tex_title: On Generalization of Decentralized Learning with Separable Data
firstpage: 4917
lastpage: 4945
page: 4917-4945
order: 4917
cycles: false
bibtex_author: Taheri, Hossein and Thrampoulidis, Christos
author:
- given: Hossein
  family: Taheri
- given: Christos
  family: Thrampoulidis
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/taheri23a/taheri23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
