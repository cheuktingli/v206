---
title: Coordinate Descent for SLOPE
software: https://github.com/jolars/slopecd
abstract: The lasso is the most famous sparse regression and feature selection method.
  One reason for its popularity is the speed at which the underlying optimization
  problem can be solved. Sorted L-One Penalized Estimation (SLOPE) is a generalization
  of the lasso with appealing statistical properties. In spite of this, the method
  has not yet reached widespread interest. A major reason for this is that current
  software packages that fit SLOPE rely on algorithms that perform poorly in high
  dimensions. To tackle this issue, we propose a new fast algorithm to solve the SLOPE
  optimization problem, which combines proximal gradient descent and proximal coordinate
  descent steps. We provide new results on the directional derivative of the SLOPE
  penalty and its related SLOPE thresholding operator, as well as provide convergence
  guarantees for our proposed solver. In extensive benchmarks on simulated and real
  data, we demonstrate our methodâ€™s performance against a long list of competing algorithms.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: larsson23a
month: 0
tex_title: Coordinate Descent for SLOPE
firstpage: 4802
lastpage: 4821
page: 4802-4821
order: 4802
cycles: false
bibtex_author: Larsson, Johan and Klopfenstein, Quentin and Massias, Mathurin and
  Wallin, Jonas
author:
- given: Johan
  family: Larsson
- given: Quentin
  family: Klopfenstein
- given: Mathurin
  family: Massias
- given: Jonas
  family: Wallin
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/larsson23a/larsson23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
