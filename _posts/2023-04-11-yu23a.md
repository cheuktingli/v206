---
title: Optimal Sample Complexity Bounds for Non-convex Optimization under Kurdyka-Lojasiewicz
  Condition
abstract: Optimization of smooth reward functions under bandit feedback is a long-standing
  problem in online learning. This paper approaches this problem by studying the convergence
  under smoothness and Kurdyka-Lojasiewicz conditions. We designed a search-based
  algorithm that achieves an improved rate compared to the standard gradient-based
  method. In conjunction with a matching lower bound, this algorithm shows optimality
  in the dependence on precision for the low-dimension regime.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yu23a
month: 0
tex_title: Optimal Sample Complexity Bounds for Non-convex Optimization under Kurdyka-Lojasiewicz
  Condition
firstpage: 6806
lastpage: 6821
page: 6806-6821
order: 6806
cycles: false
bibtex_author: Yu, Qian and Wang, Yining and Huang, Baihe and Lei, Qi and Lee, Jason
  D.
author:
- given: Qian
  family: Yu
- given: Yining
  family: Wang
- given: Baihe
  family: Huang
- given: Qi
  family: Lei
- given: Jason D.
  family: Lee
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/yu23a/yu23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
