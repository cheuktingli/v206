---
title: Tighter PAC-Bayes Generalisation Bounds by Leveraging Example Difficulty
software: https://github.com/biggs/tighter-pac-bayes-difficulty
abstract: We introduce a modified version of the excess risk, which can be used to
  obtain empirically tighter, faster-rate PAC-Bayesian generalisation bounds. This
  modified excess risk leverages information about the relative hardness of data examples
  to reduce the variance of its empirical counterpart, tightening the bound. We combine
  this with a new bound for [$-$1, 1]-valued (and potentially non-independent) signed
  losses, which is more favourable when they empirically have low variance around
  0. The primary new technical tool is a novel result for sequences of interdependent
  random vectors which may be of independent interest. We empirically evaluate these
  new bounds on a number of real-world datasets.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: biggs23a
month: 0
tex_title: Tighter PAC-Bayes Generalisation Bounds by Leveraging Example Difficulty
firstpage: 8165
lastpage: 8182
page: 8165-8182
order: 8165
cycles: false
bibtex_author: Biggs, Felix and Guedj, Benjamin
author:
- given: Felix
  family: Biggs
- given: Benjamin
  family: Guedj
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/biggs23a/biggs23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
