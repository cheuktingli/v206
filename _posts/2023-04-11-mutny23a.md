---
title: Active Exploration via Experiment Design in Markov Chains
software: https://github.com/Mojusko/experiment-design-mdp
abstract: A key challenge in science and engineering is to design experiments to learn
  about some unknown quantity of interest. Classical experimental design optimally
  allocates the experimental budget into measurements to maximize a notion of utility
  (e.g., reduction in uncertainty about the unknown quantity). We consider a rich
  setting, where the experiments are associated with states in a Markov chain, and
  we can only choose them by selecting a policy controlling the state transitions.
  This problem captures important applications, from exploration in reinforcement
  learning to spatial monitoring tasks. We propose an algorithm – markov-design –
  that efficiently selects policies whose measurement allocation provably converges
  to the optimal one. The algorithm is sequential in nature, adapting its choice of
  policies (experiments) using past measurements. In addition to our theoretical analysis,
  we demonstrate our framework on applications in ecological surveillance and pharmacology.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mutny23a
month: 0
tex_title: Active Exploration via Experiment Design in Markov Chains
firstpage: 7349
lastpage: 7374
page: 7349-7374
order: 7349
cycles: false
bibtex_author: Mutny, Mojmir and Janik, Tadeusz and Krause, Andreas
author:
- given: Mojmir
  family: Mutny
- given: Tadeusz
  family: Janik
- given: Andreas
  family: Krause
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/mutny23a/mutny23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
