---
title: Conformal Off-Policy Prediction
software: https://github.com/yyzhangecnu/COPP
abstract: Off-policy evaluation is critical in a number of applications where new
  policies need to be evaluated offline before online deployment. Most existing methods
  focus on the expected return, define the target parameter through averaging and
  provide a point estimator only. In this paper, we develop a novel procedure to produce
  reliable interval estimators for a target policyâ€™s return starting from any initial
  state. Our proposal accounts for the variability of the return around its expectation,
  focuses on the individual effect and offers valid uncertainty quantification. Our
  main idea lies in designing a pseudo policy that generates subsamples as if they
  were sampled from the target policy so that existing conformal prediction algorithms
  are applicable to prediction interval construction. Our methods are justified by
  theories, synthetic data and real data from short-video platforms.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang23c
month: 0
tex_title: Conformal Off-Policy Prediction
firstpage: 2751
lastpage: 2768
page: 2751-2768
order: 2751
cycles: false
bibtex_author: Zhang, Yingying and Shi, Chengchun and Luo, Shikai
author:
- given: Yingying
  family: Zhang
- given: Chengchun
  family: Shi
- given: Shikai
  family: Luo
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/zhang23c/zhang23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
