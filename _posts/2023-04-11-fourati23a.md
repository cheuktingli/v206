---
title: Randomized Greedy Learning for Non-monotone Stochastic Submodular Maximization
  Under Full-bandit Feedback
software: https://github.com/fouratifares/RGL
abstract: We investigate the problem of unconstrained combinatorial multi-armed bandits
  with full-bandit feedback and stochastic rewards for submodular maximization. Previous
  works investigate the same problem assuming a submodular and monotone reward function.
  In this work, we study a more general problem, i.e., when the reward function is
  not necessarily monotone, and the submodularity is assumed only in expectation.
  We propose Randomized Greedy Learning (RGL) algorithm and theoretically prove that
  it achieves a $\frac{1}{2}$-regret upper bound of $\tilde{\mathcal{O}}(n T^{\frac{2}{3}})$
  for horizon $T$ and number of arms $n$. We also show in experiments that RGL empirically
  outperforms other full-bandit variants in submodular and non-submodular settings.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fourati23a
month: 0
tex_title: Randomized Greedy Learning for Non-monotone Stochastic Submodular Maximization
  Under Full-bandit Feedback
firstpage: 7455
lastpage: 7471
page: 7455-7471
order: 7455
cycles: false
bibtex_author: Fourati, Fares and Aggarwal, Vaneet and Quinn, Christopher and Alouini,
  Mohamed-Slim
author:
- given: Fares
  family: Fourati
- given: Vaneet
  family: Aggarwal
- given: Christopher
  family: Quinn
- given: Mohamed-Slim
  family: Alouini
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/fourati23a/fourati23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
