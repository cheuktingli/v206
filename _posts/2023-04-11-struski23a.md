---
title: Bounding Evidence and Estimating Log-Likelihood in VAE
software: https://github.com/gmum/Bounding_Evidence_Estimating_LL
abstract: Many crucial problems in deep learning and statistical inference are caused
  by a variational gap, i.e., a difference between model evidence (log-likelihood)
  and evidence lower bound (ELBO). In particular, in a classical VAE setting that
  involves training via an ELBO cost function, it is difficult to provide a robust
  comparison of the effects of training between models, since we do not know a log-likelihood
  of data (but only its lower bound). In this paper, to deal with this problem, we
  introduce a general and effective upper bound, which allows us to efficiently approximate
  the evidence of data. We provide extensive theoretical and experimental studies
  of our approach, including its comparison to the other state-of-the-art upper bounds,
  as well as its application as a tool for the evaluation of models that were trained
  on various lower bounds.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: struski23a
month: 0
tex_title: Bounding Evidence and Estimating Log-Likelihood in VAE
firstpage: 5036
lastpage: 5051
page: 5036-5051
order: 5036
cycles: false
bibtex_author: Struski, {\L}ukasz and Mazur, Marcin and Batorski, Pawe{\l} and Spurek,
  Przemys{\l}aw and Tabor, Jacek
author:
- given: Łukasz
  family: Struski
- given: Marcin
  family: Mazur
- given: Paweł
  family: Batorski
- given: Przemysław
  family: Spurek
- given: Jacek
  family: Tabor
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/struski23a/struski23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
