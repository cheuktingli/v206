---
title: Online Linearized LASSO
abstract: Sparse regression has been a popular approach to perform variable selection
  and enhance the prediction accuracy and interpretability of the resulting statistical
  model. Existing approaches focus on offline regularized regression, while the online
  scenario has rarely been studied. In this paper, we propose a novel online sparse
  linear regression framework for analyzing streaming data when data points arrive
  sequentially. Our proposed method is memory efficient and requires less stringent
  restricted strong convexity assumptions. Theoretically, we show that with a properly
  chosen regularization parameter, the $\ell_2$-error of our estimator decays to zero
  at the optimal order of $\tilde \mathcal{O}(\frac{s}{\sqrt{t}})$, where $s$ is the
  sparsity level, $t$ is the streaming sample size, and $\tilde \mathcal{O}(\cdot)$
  hides logarithmic terms. Numerical experiments demonstrate the practical efficiency
  of our algorithm.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang23g
month: 0
tex_title: Online Linearized LASSO
firstpage: 7594
lastpage: 7610
page: 7594-7610
order: 7594
cycles: false
bibtex_author: Yang, Shuoguang and Yan, Yuhao and Zhu, Xiuneng and Sun, Qiang
author:
- given: Shuoguang
  family: Yang
- given: Yuhao
  family: Yan
- given: Xiuneng
  family: Zhu
- given: Qiang
  family: Sun
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/yang23g/yang23g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
