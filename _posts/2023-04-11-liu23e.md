---
title: Nonstationary Bandit Learning via Predictive Sampling
abstract: Thompson sampling has proven effective across a wide range of stationary
  bandit environments. However, as we demonstrate in this paper, it can perform poorly
  when applied to nonstationary environments. We show that such failures are attributed
  to the fact that, when exploring, the algorithm does not differentiate actions based
  on how quickly the information acquired loses its usefulness due to nonstationarity.
  Building upon this insight, we propose predictive sampling, an algorithm that deprioritizes
  acquiring information that quickly loses usefulness. Theoretical guarantee on the
  performance of predictive sampling is established through a Bayesian regret bound.
  We provide versions of predictive sampling for which computations tractably scale
  to complex bandit environments of practical interest. Through numerical simulation,
  we demonstrate that predictive sampling outperforms Thompson sampling in all nonstationary
  environments examined.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu23e
month: 0
tex_title: Nonstationary Bandit Learning via Predictive Sampling
firstpage: 6215
lastpage: 6244
page: 6215-6244
order: 6215
cycles: false
bibtex_author: Liu, Yueyang and Van Roy, Benjamin and Xu, Kuang
author:
- given: Yueyang
  family: Liu
- given: Benjamin
  family: Van Roy
- given: Kuang
  family: Xu
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/liu23e/liu23e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
