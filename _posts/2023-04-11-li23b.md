---
title: A Statistical Analysis of Polyak-Ruppert Averaged Q-Learning
abstract: We study Q-learning with Polyak-Ruppert averaging (a.k.a., averaged Q-learning)
  in a discounted markov decision process in synchronous and tabular settings. Under
  a Lipschitz condition, we establish a functional central limit theorem for the averaged
  iteration $\bar{\mathbf{Q}}_T$ and show that its standardized partial-sum process
  converges weakly to a rescaled Brownian motion. The FCLT implies a fully online
  inference method for reinforcement learning. Furthermore, we show that $\bar{\mathbf{Q}}_T$
  is the regular asymptotically linear (RAL) estimator for the optimal Q-value function
  $\mathbf{Q}^*$ that has the most efficient influence function. We present a nonasymptotic
  analysis for the $\ell_{\infty}$ error, $\mathbb{E}\|\bar{\mathbf{Q}}_T-\mathbf{Q}^*\|_{\infty}$,
  showing that it matches the instance-dependent lower bound for polynomial step sizes.
  Similar results are provided for entropy-regularized Q-Learning without the Lipschitz
  condition.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23b
month: 0
tex_title: A Statistical Analysis of Polyak-Ruppert Averaged Q-Learning
firstpage: 2207
lastpage: 2261
page: 2207-2261
order: 2207
cycles: false
bibtex_author: Li, Xiang and Yang, Wenhao and Liang, Jiadong and Zhang, Zhihua and
  Jordan, Michael I.
author:
- given: Xiang
  family: Li
- given: Wenhao
  family: Yang
- given: Jiadong
  family: Liang
- given: Zhihua
  family: Zhang
- given: Michael I.
  family: Jordan
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/li23b/li23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
