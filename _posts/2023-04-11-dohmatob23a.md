---
title: Origins of Low-Dimensional Adversarial Perturbations
abstract: 'Machine learning models are known to be susceptible to adversarial perturbations.
  Even more concerning is the fact that these adversarial perturbations can be found
  by black-box search using surprisingly few queries, which essentially restricts
  the perturbation to a subspace of dimension $k$â€”much smaller than the dimension
  $d$ of the image space. This intriguing phenomenon raises the question: Is the vulnerability
  to black-box attacks inherent or can we hope to prevent them? In this paper, we
  initiate a rigorous study of the phenomenon of low-dimensional adversarial perturbations
  (LDAPs). Our result characterizes precisely the sufficient conditions for the existence
  of LDAPs, and we show that these conditions hold for neural networks under practical
  settings, including the so-called lazy regime wherein the parameters of the trained
  network remain close to their values at initialization. Our theoretical results
  are confirmed by experiments on both synthetic and real data.'
section: Notable Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dohmatob23a
month: 0
tex_title: Origins of Low-Dimensional Adversarial Perturbations
firstpage: 9221
lastpage: 9237
page: 9221-9237
order: 9221
cycles: false
bibtex_author: Dohmatob, Elvis and Guo, Chuan and Goibert, Morgane
author:
- given: Elvis
  family: Dohmatob
- given: Chuan
  family: Guo
- given: Morgane
  family: Goibert
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/dohmatob23a/dohmatob23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
