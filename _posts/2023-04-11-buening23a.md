---
title: Minimax-Bayes Reinforcement Learning
software: https://github.com/minimaxBRL/minimax-bayes-rl
abstract: While the Bayesian decision-theoretic framework offers an elegant solution
  to the problem of decision making under uncertainty, one question is how to appropriately
  select the prior distribution. One idea is to employ a worst-case prior. However,
  this is not as easy to specify in sequential decision making as in simple statistical
  estimation problems. This paper studies (sometimes approximate) minimax-Bayes solutions
  for various reinforcement learning problems to gain insights into the properties
  of the corresponding priors and policies. We find that while the worst-case prior
  depends on the setting, the corresponding minimax policies are more robust than
  those that assume a standard (i.e. uniform) prior.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: buening23a
month: 0
tex_title: Minimax-Bayes Reinforcement Learning
firstpage: 7511
lastpage: 7527
page: 7511-7527
order: 7511
cycles: false
bibtex_author: Buening, Thomas Kleine and Dimitrakakis, Christos and Eriksson, Hannes
  and Grover, Divya and Jorge, Emilio
author:
- given: Thomas Kleine
  family: Buening
- given: Christos
  family: Dimitrakakis
- given: Hannes
  family: Eriksson
- given: Divya
  family: Grover
- given: Emilio
  family: Jorge
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/buening23a/buening23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
