---
title: 'ForestPrune: Compact Depth-Pruned Tree Ensembles'
software: https://github.com/brianliu12437/ForestPruneAISTATS2023
abstract: Tree ensembles are powerful models that achieve excellent predictive performances,
  but can grow to unwieldy sizes. These ensembles are often post-processed (pruned)
  to reduce memory footprint and improve interpretability. We present ForestPrune,
  a novel optimization framework to post-process tree ensembles by pruning depth layers
  from individual trees. Since the number of nodes in a decision tree increases exponentially
  with tree depth, pruning deep trees drastically compactifies ensembles. We develop
  a specialized optimization algorithm to efficiently obtain high-quality solutions
  to problems under ForestPrune. Our algorithm typically reaches good solutions in
  seconds for medium-size datasets and ensembles, with 10000s of rows and 100s of
  trees, resulting in significant speedups over existing approaches. Our experiments
  demonstrate that ForestPrune produces parsimonious models that outperform models
  extracted by existing post-processing algorithms.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu23h
month: 0
tex_title: 'ForestPrune: Compact Depth-Pruned Tree Ensembles'
firstpage: 9417
lastpage: 9428
page: 9417-9428
order: 9417
cycles: false
bibtex_author: Liu, Brian and Mazumder, Rahul
author:
- given: Brian
  family: Liu
- given: Rahul
  family: Mazumder
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/liu23h/liu23h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
