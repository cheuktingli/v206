---
title: Reconstructing Training Data from Model Gradient, Provably
abstract: 'Understanding when and how much a model gradient leaks information about
  the training sample is an important question in privacy. In this paper, we present
  a surprising result: Even without training or memorizing the data, we can fully
  reconstruct the training samples from a single gradient query at a randomly chosen
  parameter value. We prove the identifiability of the training data under mild assumptions:
  with shallow or deep neural networks and wide range of activation functions. We
  also present a statistically and computationally efficient algorithm based on tensor
  decomposition to reconstruct the training data. As a provable attack that reveals
  sensitive training data, our findings suggest potential  severe threats to privacy,
  especially in federated learning.'
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang23g
month: 0
tex_title: Reconstructing Training Data from Model Gradient, Provably
firstpage: 6595
lastpage: 6612
page: 6595-6612
order: 6595
cycles: false
bibtex_author: Wang, Zihan and Lee, Jason and Lei, Qi
author:
- given: Zihan
  family: Wang
- given: Jason
  family: Lee
- given: Qi
  family: Lei
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/wang23g/wang23g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
