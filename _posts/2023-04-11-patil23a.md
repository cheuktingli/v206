---
title: 'Finite time analysis of temporal difference learning with linear function
  approximation: Tail averaging and regularisation'
abstract: We study the finite-time behaviour of the popular temporal difference (TD)
  learning algorithm, when combined with tail-averaging. We derive finite time bounds
  on the parameter error of the tail-averaged TD iterate under a step-size choice
  that does not require information about the eigenvalues of the matrix underlying
  the projected TD fixed point. Our analysis shows that tail-averaged TD converges
  at the optimal O (1/t) rate, both in expectation and with high probability. In addition,
  our bounds exhibit a sharper rate of decay for the initial error (bias), which is
  an improvement over averaging all iterates. We also propose and analyse a variant
  of TD that incorporates regularisation, and show that this variant fares favourably
  in problems with ill-conditioned features.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: patil23a
month: 0
tex_title: 'Finite time analysis of temporal difference learning with linear function
  approximation: Tail averaging and regularisation'
firstpage: 5438
lastpage: 5448
page: 5438-5448
order: 5438
cycles: false
bibtex_author: Patil, Gandharv and L.A., Prashanth and Nagaraj, Dheeraj and Precup,
  Doina
author:
- given: Gandharv
  family: Patil
- given: Prashanth
  family: L.A.
- given: Dheeraj
  family: Nagaraj
- given: Doina
  family: Precup
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/patil23a/patil23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
