---
title: Recurrent Neural Networks and Universal Approximation of Bayesian Filters
abstract: 'We consider the Bayesian optimal filtering problem: i.e. estimating some
  conditional statistics of a latent time-series signal from an observation sequence.
  Classical approaches often rely on the use of assumed or estimated transition and
  observation models. Instead, we formulate a generic recurrent neural network framework
  and seek to learn directly a recursive mapping from observational inputs to the
  desired estimator statistics. The main focus of this article is the approximation
  capabilities of this framework. We provide approximation error bounds for filtering
  in general non-compact domains. We also consider strong time-uniform approximation
  error bounds that guarantee good long-time performance. We discuss and illustrate
  a number of practical concerns and implications of these results.'
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bishop23a
month: 0
tex_title: Recurrent Neural Networks and Universal Approximation of Bayesian Filters
firstpage: 6956
lastpage: 6967
page: 6956-6967
order: 6956
cycles: false
bibtex_author: Bishop, Adrian N. and Bonilla, Edwin V.
author:
- given: Adrian N.
  family: Bishop
- given: Edwin V.
  family: Bonilla
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/bishop23a/bishop23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
