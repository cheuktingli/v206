---
title: Adversarial Noises Are Linearly Separable for (Nearly) Random Neural Networks
abstract: Adversarial example, which is usually generated by adding imperceptible
  adversarial noise to a clean sample, is ubiquitous for neural networks. In this
  paper we unveil a surprising property of adversarial noises when they are put together,
  i.e., adversarial noises crafted by one-step gradient methods are linearly separable
  if equipped with the corresponding labels. We theoretically prove this property
  for a two-layer network with randomly initialized entries and the neural tangent
  kernel setup where the parameters are not far from initialization. The proof idea
  is to show the label information can be efficiently backpropagated to the input
  while keeping the linear separability. Our theory and experimental evidence further
  show that the linear classifier trained with the adversarial noises of the training
  data can well classify the adversarial noises of the test data, indicating that
  adversarial noises actually inject a distributional perturbation to the original
  data distribution. Furthermore, we empirically demonstrate that the adversarial
  noises may become less linearly separable when the above conditions are compromised
  while they are still much easier to classify than original features.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang23d
month: 0
tex_title: Adversarial Noises Are Linearly Separable for (Nearly) Random Neural Networks
firstpage: 2792
lastpage: 2804
page: 2792-2804
order: 2792
cycles: false
bibtex_author: Zhang, Huishuai and Yu, Da and Lu, Yiping and He, Di
author:
- given: Huishuai
  family: Zhang
- given: Da
  family: Yu
- given: Yiping
  family: Lu
- given: Di
  family: He
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/zhang23d/zhang23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
