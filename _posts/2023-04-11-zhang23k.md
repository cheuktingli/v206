---
title: Spread Flows for Manifold Modelling
abstract: Flow-based models typically define a latent space with dimensionality identical
  to the observational space. In many problems, however, the data does not populate
  the full ambient data space that they natively reside in, rather inhabiting a lower-dimensional
  manifold. In such scenarios, flow-based models are unable to represent data structures
  exactly as their densities will always have support off the data manifold, potentially
  resulting in degradation of model performance. To address this issue, we propose
  to learn a manifold prior for flow models that leverage the recently proposed spread
  divergence towards fixing the crucial problem; the KL divergence and maximum likelihood
  estimation are ill-defined for manifold learning. In addition to improving both
  sample quality and representation quality, an auxiliary benefit enabled by our approach
  is the ability to identify the intrinsic dimension of the manifold distribution.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang23k
month: 0
tex_title: Spread Flows for Manifold Modelling
firstpage: 11435
lastpage: 11456
page: 11435-11456
order: 11435
cycles: false
bibtex_author: Zhang, Mingtian and Sun, Yitong and Zhang, Chen and Mcdonagh, Steven
author:
- given: Mingtian
  family: Zhang
- given: Yitong
  family: Sun
- given: Chen
  family: Zhang
- given: Steven
  family: Mcdonagh
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/zhang23k/zhang23k.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
