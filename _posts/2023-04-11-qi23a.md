---
title: Surveillance Evasion Through Bayesian Reinforcement Learning
software: https://github.com/eikonal-equation/Bayesian-Surveillance-Evasion
abstract: We consider a task of surveillance-evading path-planning in a continuous
  setting. An Evader strives to escape from a 2D domain while minimizing the risk
  of detection (and immediate capture). The probability of detection is path-dependent
  and determined by the spatially inhomogeneous surveillance intensity, which is fixed
  but a priori unknown and gradually learned in the multi-episodic setting. We introduce
  a Bayesian reinforcement learning algorithm that relies on a Gaussian Process regression
  (to model the surveillance intensity function based on the information from prior
  episodes), numerical methods for Hamilton-Jacobi PDEs (to plan the best continuous
  trajectories based on the current model), and Confidence Bounds (to balance the
  exploration vs exploitation). We use numerical experiments and regret metrics to
  highlight the significant advantages of our approach compared to traditional graph-based
  algorithms of reinforcement learning.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: qi23a
month: 0
tex_title: Surveillance Evasion Through Bayesian Reinforcement Learning
firstpage: 8448
lastpage: 8462
page: 8448-8462
order: 8448
cycles: false
bibtex_author: Qi, Dongping and Bindel, David and Vladimirsky, Alexander
author:
- given: Dongping
  family: Qi
- given: David
  family: Bindel
- given: Alexander
  family: Vladimirsky
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/qi23a/qi23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
