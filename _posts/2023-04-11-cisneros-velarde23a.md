---
title: 'One Policy is Enough: Parallel Exploration with a Single Policy is Near-Optimal
  for Reward-Free Reinforcement Learning'
abstract: Although parallelism has been extensively used in Reinforcement Learning
  (RL), the quantitative effects of parallel exploration are not well understood theoretically.
  We study the benefits of simple parallel exploration for reward-free RL in linear
  Markov decision processes (MDPs) and two-player zero-sum Markov games (MGs). In
  contrast to the existing literature, which focuses on approaches that encourage
  agents to explore over a diverse set of policies, we show that using a single policy
  to guide exploration across all agents is sufficient to obtain an almost-linear
  speedup in all cases compared to their fully sequential counterpart. Furthermore,
  we demonstrate that this simple procedure is near-minimax optimal in the reward-free
  setting for linear MDPs. From a practical perspective, our paper shows that a single
  policy is sufficient and provably near-optimal for incorporating parallelism during
  the exploration phase.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cisneros-velarde23a
month: 0
tex_title: 'One Policy is Enough: Parallel Exploration with a Single Policy is Near-Optimal
  for Reward-Free Reinforcement Learning'
firstpage: 1965
lastpage: 2001
page: 1965-2001
order: 1965
cycles: false
bibtex_author: Cisneros-Velarde, Pedro and Lyu, Boxiang and Koyejo, Sanmi and Kolar,
  Mladen
author:
- given: Pedro
  family: Cisneros-Velarde
- given: Boxiang
  family: Lyu
- given: Sanmi
  family: Koyejo
- given: Mladen
  family: Kolar
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/cisneros-velarde23a/cisneros-velarde23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
