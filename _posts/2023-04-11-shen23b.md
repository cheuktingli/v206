---
title: Distributed Offline Policy Optimization Over Batch Data
abstract: Federated learning (FL) has received increasing interests during the past
  years, However, most of the existing works focus on supervised learning, and federated
  learning for sequential decision making has not been fully explored. Part of the
  reason is that learning a policy for sequential decision making typically requires
  repeated interaction with the environments, which is costly in many FL applications.To
  overcome this issue, this work proposes a federated offline policy optimization
  method abbreviated as FedOPO that allows clients to jointly learn the optimal policy
  without interacting with environments during training. Albeit the nonconcave-convex-strongly
  concave nature of the resultant max-min-max problem, we establish both the local
  and global convergence of our FedOPO algorithm. Experiments on the OpenAI gym demonstrate
  that our algorithm is able to find a near-optimal policy while enjoying various
  merits brought by FL, including training speedup and improved asymptotic performance.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shen23b
month: 0
tex_title: Distributed Offline Policy Optimization Over Batch Data
firstpage: 4443
lastpage: 4472
page: 4443-4472
order: 4443
cycles: false
bibtex_author: Shen, Han and Lu, Songtao and Cui, Xiaodong and Chen, Tianyi
author:
- given: Han
  family: Shen
- given: Songtao
  family: Lu
- given: Xiaodong
  family: Cui
- given: Tianyi
  family: Chen
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/shen23b/shen23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
