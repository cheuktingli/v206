---
title: Second Order Path Variationals in Non-Stationary Online Learning
abstract: We consider the problem of universal dynamic regret minimization under exp-concave
  and smooth losses. We show that appropriately designed Strongly Adaptive algorithms
  achieve a dynamic regret of $\tilde O(d^2 n^{1/5} [\mathcal{TV}_1(w_{1:n})]^{2/5}
  \vee d^2)$, where $n$ is the time horizon and $\mathcal{TV}_1(w_{1:n})$ a path variational
  based on second order differences of the comparator sequence. Such a path variational
  naturally encodes comparator sequences that are piece-wise linear â€“ a powerful family
  that tracks a variety of non-stationarity patterns in practice (Kim et al., 2009).
  The aforementioned dynamic regret is shown to be optimal modulo dimension dependencies
  and poly-logarithmic factors of $n$. To the best of our knowledge, this path variational
  has not been studied in the non-stochastic online learning literature before. Our
  proof techniques rely on analysing the KKT conditions of the offline oracle and
  requires several non-trivial generalizations of the ideas in Baby and Wang (2021)
  where the latter work only implies an $\tilde{O}(n^{1/3})$ regret for the current
  problem.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: baby23a
month: 0
tex_title: Second Order Path Variationals in Non-Stationary Online Learning
firstpage: 9024
lastpage: 9075
page: 9024-9075
order: 9024
cycles: false
bibtex_author: Baby, Dheeraj and Wang, Yu-Xiang
author:
- given: Dheeraj
  family: Baby
- given: Yu-Xiang
  family: Wang
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/baby23a/baby23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
