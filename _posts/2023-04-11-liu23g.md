---
title: Consistent Complementary-Label Learning via Order-Preserving Losses
abstract: In contrast to ordinary supervised classification tasks that require massive
  data with high-quality labels, complementary-label learning (CLL) deals with the
  weakly-supervised learning scenario where each instance is equipped with a complementary
  label, which specifies a class the instance does not belong to. However, most of
  the existing statistically consistent CLL methods suffer from overfitting intrinsically,
  due to the negative empirical risk issue. In this paper, we aim to propose overfitting-resistant
  and theoretically grounded methods for CLL. Considering the unique property of the
  distribution of complementarily labeled samples, we provide a risk estimator via
  order-preserving losses, which are naturally non-negative and thus can avoid overfitting
  caused by negative terms in risk estimators. Moreover, we provide classifier-consistency
  analysis and statistical guarantee for this estimator. Furthermore, we provide a
  weighed version of the proposed risk estimator to further enhance its generalization
  ability and prove its statistical consistency. Experiments on benchmark datasets
  demonstrate the effectiveness of our proposed methods.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu23g
month: 0
tex_title: Consistent Complementary-Label Learning via Order-Preserving Losses
firstpage: 8734
lastpage: 8748
page: 8734-8748
order: 8734
cycles: false
bibtex_author: Liu, Shuqi and Cao, Yuzhou and Zhang, Qiaozhen and Feng, Lei and An,
  Bo
author:
- given: Shuqi
  family: Liu
- given: Yuzhou
  family: Cao
- given: Qiaozhen
  family: Zhang
- given: Lei
  family: Feng
- given: Bo
  family: An
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/liu23g/liu23g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
