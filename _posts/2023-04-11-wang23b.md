---
title: A Finite Sample Complexity Bound for Distributionally Robust Q-learning
software: https://github.com/Shengbo-Wang/AISTATS2023_DRRL_MLMC_code.git
abstract: We consider a reinforcement learning setting in which the deployment environment
  is different from the training environment. Applying a robust Markov decision processes
  formulation, we extend the distributionally robust Q-learning framework studied
  in [Liu et. al. 2022]. Further, we improve the design and analysis of their multi-level
  Monte Carlo estimator. Assuming access to a simulator, we prove that the worst-case
  expected sample complexity of our algorithm to learn the optimal robust Q-function
  within an $\epsilon$ error in the sup norm is upper bounded by $\tilde O(|S||A|(1-\gamma)^{-5}\epsilon^{-2}p_{\wedge}^{-6}\delta^{-4})$,
  where $\gamma$ is the discount rate, $p_{\wedge}$ is the non-zero minimal support
  probability of the transition kernels and $\delta$ is the uncertainty size. This
  is the first sample complexity result for the model-free robust RL problem. Simulation
  studies further validate our theoretical results.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang23b
month: 0
tex_title: A Finite Sample Complexity Bound for Distributionally Robust Q-learning
firstpage: 3370
lastpage: 3398
page: 3370-3398
order: 3370
cycles: false
bibtex_author: Wang, Shengbo and Si, Nian and Blanchet, Jose and Zhou, Zhengyuan
author:
- given: Shengbo
  family: Wang
- given: Nian
  family: Si
- given: Jose
  family: Blanchet
- given: Zhengyuan
  family: Zhou
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/wang23b/wang23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
