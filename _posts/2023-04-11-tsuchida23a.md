---
title: Deep equilibrium models as estimators for continuous latent variables
software: https://github.com/RussellTsuchida/ped
abstract: 'Principal Component Analysis (PCA) and its exponential family extensions
  have three components: observations, latents and parameters of a linear transformation.
  We consider a generalised setting where the canonical parameters of the exponential
  family are a nonlinear transformation of the latents. We show explicit relationships
  between particular neural network architectures and the corresponding statistical
  models. We find that deep equilibrium models — a recently introduced class of implicit
  neural networks — solve maximum a-posteriori (MAP) estimates for the latents and
  parameters of the transformation. Our analysis provides a systematic way to relate
  activation functions, dropout, and layer structure, to statistical assumptions about
  the observations, thus providing foundational principles for unsupervised DEQs.
  For hierarchical latents, individual neurons can be interpreted as nodes in a deep
  graphical model. Our DEQ feature maps are end-to-end differentiable, enabling fine-tuning
  for downstream tasks.'
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tsuchida23a
month: 0
tex_title: Deep equilibrium models as estimators for continuous latent variables
firstpage: 1646
lastpage: 1671
page: 1646-1671
order: 1646
cycles: false
bibtex_author: Tsuchida, Russell and Ong, Cheng Soon
author:
- given: Russell
  family: Tsuchida
- given: Cheng Soon
  family: Ong
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/tsuchida23a/tsuchida23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
