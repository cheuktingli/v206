---
title: Active Learning for Single Neuron Models with Lipschitz Non-Linearities
abstract: We consider the problem of active learning for single neuron models, also
  sometimes called “ridge functions”, in the agnostic setting (under adversarial label
  noise). Such models have been shown to be broadly effective in modeling physical
  phenomena, and for constructing surrogate data-driven models for partial differential
  equations. Surprisingly, we show that for a single neuron model with any Lipschitz
  non-linearity (such as the ReLU, sigmoid, absolute value, low-degree polynomial,
  among others), strong provable approximation guarantees can be obtained using a
  well-known active learning strategy for fitting linear functions in the agnostic
  setting. Namely, we can collect samples via statistical leverage score sampling,
  which has been shown to be nearoptimal in other active learning scenarios. We support
  our theoretical results with empirical simulations showing that our proposed active
  learning strategy based on leverage score sampling outperforms (ordinary) uniform
  sampling when fitting single neuron models.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gajjar23a
month: 0
tex_title: Active Learning for Single Neuron Models with Lipschitz Non-Linearities
firstpage: 4101
lastpage: 4113
page: 4101-4113
order: 4101
cycles: false
bibtex_author: Gajjar, Aarshvi and Musco, Christopher and Hegde, Chinmay
author:
- given: Aarshvi
  family: Gajjar
- given: Christopher
  family: Musco
- given: Chinmay
  family: Hegde
date: 2023-04-11
address:
container-title: Proceedings of The 26th International Conference on Artificial Intelligence
  and Statistics
volume: '206'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 11
pdf: https://proceedings.mlr.press/v206/gajjar23a/gajjar23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
